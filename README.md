Numpy Scientific computing http://numpy.org
Pandas data analysis and manipulation tool
Matplotlib generate graph http://matplotlib.org
sk-learn environment important

clustering 分组
jiangwei

数字存 1000 万训练集
字母存 2000 万训练集

概率论
线性代数
离散数学

KNN K-Nearest Neighbor 最邻近算法

数据集分为训练集和测试集
训练集数据越多，精确度越高
原则上测试集不应该超过 1/4，若测试集超过 50%，则没有什么意义
测试集用于测试训练结果的准确度
一般 data(feature) 为 X，target(label) 为 y
X_train 训练集数据
y_train 训练集 target
X_test 测试集数据
y_test 测试集 target

n-fold

逻辑回归算法

决策树分类算法
用例：根据体检各项指标，使用决策树判定得到语料建议 - 曲阳医院

graphviz 以图像化方式展示决策树
pip install pydotplus
对于不是 .whl 而是 .tar.gz 的依赖，解压后执行 python setup.py install 即可安装

使用预处理（preprocessing）对数据预处理，将原有数据中的单词等数据转换成数学代号，如数字，以方便分析

梯度递增算法

Understanding the data -> Preprocessing the data -> Spot checking algorithms    -> Finalize the model
数据理解                -> 预处理、清洗数据        -> 找出适合的模型、算法（最费时）-> 模型固化（将模型保存到文件中，下次可直接加载模型文件，并对新数据进行分析、预测）
为每种算法构建一个 pipeline，自动跑完算有算法，出报告图，决定最终使用哪种算法


KFold 用于检测算法的优劣
如 k = 2，表示 2 折
k = 10，表示 10 折，将数据平均分为 10 份，先以第一份数据作为测试集，剩余 9 份作为训练集计算出分数；然后以第二份数据作为测试集，剩余 9 份作为训练集计算出分数，以此类推计算出 10 个分数，计算出平均值。
使用 metrics 对算法的计算结果计算精准度每次都不一样，因为虽然指定了测试集的大小，但每次划分训练集合测试集中的数据并不一样，而KFold 对算法每次计算结果得出的分数都是相同的
KFold 分组时，可能会出现数据分布不均匀，如对于糖尿病数据集为例，KFold 分组中可能会出现一组中 label 全为 1 或大部分为 1，另一组 label 全为 0 或大部分为 0，这样这两组计算出的分数肯定会有很大差异
StratifiedKFold 可以均匀的分组，保证各组 label 分布均匀

模糊矩阵 Confusion Matrix，横向代表真实的值，纵向代表算法的预测值，对角线外的非 0 数字越少越好，如果非 0 数字全在对角线上，则说明预测精准度为 100%
如：y_test:
[2 5 2 3 7 6 0 2 2 6 5 1 9 0 9 7 2 2 6 0 2 8 9 5 1 2 5 2 1 7 4 6 6 2 4 1 6
 1 8 6 1 2 6 0 1 4 6 8 7 1 2 3 9 9 0 0 4 3 9 4 8 4 4 4 8 1 5 3 0 9 9 6 2 5
 3 5 5 0 8 0 3 8 3 0 1 9 2 4 1 2 8 5 1 7 1 1 4 2 8 6 7 5 7 7 3 3 9 9 5 9 0
 1 8 0 8 9 3 0 7 5 9 7 7 8 9 4 0 9 7 6 4 1 9 6 6 2 0 7 1 9 0 0 7 1 5 4 2 4
 4 5 2 7 1 9 3 1 9 1 0 1 9 3 5 5 0 8 1 7 3 4 5 8 0 0 4 3 8 9 4 4 4 9 8 7 9
 5 3 4 6 6 4 6 1 9 7 7 8 4 3 5 4 1 2 5 1 8 5 8 2 9 0 5 5 3 3 3 4 6 1 4 6 6
 9 9 2 4 0 7 8 2 3 0 7 3 0 3 5 3 6 3 0 6 9 0 8 5 8 0 2 3 1 2 2 5 4 1 6 0 9
 0 2 7 5 7 1 3 5 6 2 3 9 8 5 1 2 2 7 6 8 6 3 5 9 4 2 6 8 5 2 9 6 6 0 9 0 2
 3 6 2 4 6 6 8 9 3 8 7 1 1 7 9 5 5 8 8 7 1 0 2 2 3 1 9 0 6 8 5 8 4 1 1 8 8
 2 3 1 8 6 3 1 5 3 1 4 7 4 3 0 6 5 0 8 2 5 6 1 6 5 7 7]
 y_pred:
 [2 5 2 3 7 6 0 2 2 6 5 1 9 0 9 7 2 2 6 0 2 8 9 5 1 2 5 2 1 7 4 6 6 2 4 1 6
 1 1 6 1 2 6 0 1 4 6 8 7 1 2 3 9 9 0 0 4 3 9 4 8 4 4 4 8 1 5 3 0 9 9 6 2 5
 3 5 5 0 8 0 3 8 3 0 1 9 2 4 1 2 8 5 1 7 1 1 4 2 8 6 7 5 7 7 3 3 9 9 5 9 0
 1 8 0 8 9 3 0 7 5 9 7 7 8 9 4 0 9 7 6 4 1 9 6 6 2 0 7 1 9 0 0 7 1 5 4 2 4
 4 5 2 7 1 9 3 1 9 1 0 1 9 3 5 5 0 8 1 7 3 4 5 8 0 0 4 3 8 9 4 4 4 9 8 7 9
 5 3 4 6 6 4 6 1 9 7 7 8 4 3 5 4 1 2 5 1 8 5 8 2 9 0 5 5 3 3 3 4 6 1 4 6 6
 4 9 2 4 0 7 8 2 3 0 7 3 0 3 5 3 6 3 0 6 9 0 8 5 8 0 2 3 1 2 2 5 4 1 6 0 9
 0 2 7 5 7 1 3 5 6 2 3 9 8 5 1 2 2 7 6 8 6 3 5 9 4 2 6 8 5 2 9 6 6 0 9 0 2
 3 6 2 4 6 6 8 9 3 8 7 1 1 7 9 5 5 8 8 7 1 0 2 2 3 1 9 0 6 8 5 8 4 1 1 8 8
 2 3 1 8 6 3 1 5 3 1 4 7 4 3 0 6 5 0 8 2 5 6 1 6 5 9 7]
得到的模糊矩阵如下：
[[36  0  0  0  0  0  0  0  0  0]
 [ 0 41  0  0  0  0  0  0  0  0]
 [ 0  0 38  0  0  0  0  0  0  0]
 [ 0  0  0 35  0  0  0  0  0  0]
 [ 0  0  0  0 33  0  0  0  0  0]
 [ 0  0  0  0  0 38  0  0  0  0]
 [ 0  0  0  0  0  0 37  0  0  0]
 [ 0  0  0  0  0  0  0 29  0  1]
 [ 0  1  0  0  0  0  0  0 34  0]
 [ 0  0  0  0  1  0  0  0  0 36]]
- 第 0 行第 0 列，表示真实的 0 总共有 36 个，预测的 0 总共有 36 个，说明真实数据和预测数据完全吻合
- 第 1 行第 1 列，表示真实的 1 总共有 41 个，但预测的 1 总共有 41 + 1 = 42 个
- 第 2 行第 2 列，表示真实的 2 总共有 38 个，预测的 2 总共有 38 个，说明真实数据和预测数据完全吻合
- 第 3 行第 3 列，表示真实的 3 总共有 35 个，预测的 3 总共有 35 个，说明真实数据和预测数据完全吻合
- 第 4 行第 4 列，表示真实的 4 总共有 33 个，预测的 4 总共有 33 + 1 = 34 个
- 第 5 行第 5 列，表示真实的 5 总共有 38 个，预测的 5 总共有 38 个，说明真实数据和预测数据完全吻合
- 第 6 行第 6 列，表示真实的 6 总共有 37 个，预测的 6 总共有 37 个，说明真实数据和预测数据完全吻合
- 第 7 行第 7 列，表示真实的 7 总共有 29 + 1 = 30 个，但预测的 7 只有 29 个
- 第 8 行第 8 列，表示真实的 8 总共有 34 + 1 = 35 个，但预测的 8 只有 34 个
- 第 9 行第 9 列，表示真实的 9 总共有 36 + 1 = 37 个，预测的 9 总共有 36 + 1 = 37 个，但并不能代表真实数据和预测数据完全吻合，因为真实数据中的一个 9 被预测成了 4，预测数据中的一个 9 实际上是真实数据的 7

## 数据来源
- sk_learn
- UCI
- DG(Data Generator)
- 自己造数据

## 考试相关
- 单选题
- 编程题
    - KMeans 必考
- 爬虫
